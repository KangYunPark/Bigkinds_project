{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMp81dpJv2qOe2ZU9CIL6tQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6dQFSlQrj3j9"},"outputs":[],"source":["########## 벤치마크 데이터 만들기 (빅카인즈 기사 6만건) ##########\n","\n","##### API로 데이터 불러오기 #####\n","\n","from urllib import request, parse\n","import pandas as pd\n","import json\n","from pandas.io.json import json_normalize\n","\n","headers = {'Content-Type': 'application/json; chearset=utf-8'}\n","\n","# news_provider = ['경향신문','국민일보','내일신문','동아일보', '문화일보','서울신문','세계일보','조선일보', '중앙일보','한겨례','한국일보','경기일보', '경인일보','강원도민일보','강원일보','대전일보',\n","#                 '중도일보','중부매일','중부일보','충북일보', '충청일보','충청투데이','경남신문','경남도민일보', '경상일보','국제신문','대구일보','매일신문', '부산일보','영남일보','울산매일','광주매일신문',\n","#                 '광주일보','무등일보','전남일보','전북도민일보', '전북일보','제민일보','한라일보','매일경제','머니투데이', '서울경제','파이낸셜뉴스','한국경제','헤럴드경제','아시아경제', '아주경제','전자신문','디지털타임스']\n","# no_society_provider = ['한겨례', '한국일보', '매일경제'] : 세개 신문사에는 '사회'카테고리에 보도된 기사 없음\n","\n","major_provider = ['조선일보', '중앙일보', '동아일보']\n","\n","json_file1 = pd.DataFrame()\n","\n","for i in major_provider :\n","  data = {\n","      'access_key': 'c623a12a-2a15-44bc-8d93-183b5b6834b4',\n","      'argument': {\n","          #'query' : '취업',\n","          'published_at': {\n","              'from' : '2021-08-01',\n","              'until' : '2022-08-01'\n","              },\n","          'provider' : [i],\n","          'category' : ['사회', '경제', '정치', '문화'],\n","          'return_from' : 1,\n","          'return_size' :10000,\n","          'fields' : ['content' ,'category']\n","        }\n","        }\n","  req = request.Request('http://tools.kinds.or.kr:8888/search/news', headers=headers, data=json.dumps(data).encode('utf-8'))\n","  res = request.urlopen(req)\n","\n","  json_str = res.read().decode('utf-8')\n","  json_object = json.loads(json_str)\n","  json_df = json_normalize(json_object['return_object']['documents'])\n","  json_file1 = pd.concat([json_file1,json_df], ignore_index=True)\n","\n","json_file2 = pd.DataFrame()\n","\n","for i in major_provider :\n","  data = {\n","      'access_key': 'c623a12a-2a15-44bc-8d93-183b5b6834b4',\n","      'argument': {\n","          #'query' : '취업',\n","          'published_at': {\n","              'from' : '2021-08-01',\n","              'until' : '2022-08-01'\n","              },\n","          'provider' : [i],\n","          'category' : ['사회', '경제', '정치', '문화'],\n","          'return_from' : 10001,\n","          'return_size' :10000,\n","          'fields' : ['content' ,'category']\n","        }\n","        }\n","  req = request.Request('http://tools.kinds.or.kr:8888/search/news', headers=headers, data=json.dumps(data).encode('utf-8'))\n","  res = request.urlopen(req)\n","\n","  json_str = res.read().decode('utf-8')\n","  json_object = json.loads(json_str)\n","  json_df = json_normalize(json_object['return_object']['documents'])\n","  json_file2 = pd.concat([json_file2,json_df], ignore_index=True)\n","\n","\n","# 예비용\n","json_file3 = pd.DataFrame()\n","\n","for i in major_provider :\n","  data = {\n","      'access_key': 'c623a12a-2a15-44bc-8d93-183b5b6834b4',\n","      'argument': {\n","          #'query' : '취업',\n","          'published_at': {\n","              'from' : '2021-08-01',\n","              'until' : '2022-08-01'\n","              },\n","          'provider' : [i],\n","          'category' : ['사회', '경제', '정치', '문화'],\n","          'return_from' : 20001,\n","          'return_size' :1000,\n","          'fields' : ['content' ,'category']\n","        }\n","        }\n","  req = request.Request('http://tools.kinds.or.kr:8888/search/news', headers=headers, data=json.dumps(data).encode('utf-8'))\n","  res = request.urlopen(req)\n","\n","  json_str = res.read().decode('utf-8')\n","  json_object = json.loads(json_str)\n","  json_df = json_normalize(json_object['return_object']['documents'])\n","  json_file3 = pd.concat([json_file3,json_df], ignore_index=True)"]},{"cell_type":"code","source":["##### rawraw : API로 불러온 63000개의 기사 #####\n","rawraw = pd.concat([json_file1, json_file2, json_file3], ignore_index=True)\n","\n","##### benchmark : 작업 진행 할 데이터 프레임 #####\n","benchmark = pd.DataFrame()\n","benchmark = pd.concat([benchmark, rawraw], ignore_index= True)"],"metadata":{"id":"i3bBLpl1kn6t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### 데이터 전처리 #####\n","##### title [부음], [인사]로 시작하는 기사 제거\n","for i in range(len(benchmark)) :\n","  if benchmark['title'][i].startswith('[부음]') or benchmark['title'][i].startswith('[인사]') :\n","    benchmark.drop(i, inplace=True)\n","len(benchmark)"],"metadata":{"id":"OpAlOvGKkv2F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### 중복기사제거\n","remove_index = benchmark[benchmark.duplicated(['content'])].index\n","benchmark.drop(remove_index, inplace=True)\n","len(benchmark)"],"metadata":{"id":"gxNng-i0lHq8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###### benchmark 데이터 6만개로 맞추기 #####\n","benchmark = benchmark[:60000]\n","benchmark.reset_index(drop = True, inplace = True)  # 인덱스 초기화"],"metadata":{"id":"d2yetZBslLM1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### csv 파일로 저장 #####\n","# benchmark.to_csv('benchmark_data_60000.csv', encoding = 'utf-8-sig')"],"metadata":{"id":"bWvKIyHnlYnd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["########## 데이터 전처리 ##########\n","import re"],"metadata":{"id":"qAEYSxofld60"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###### 본문만 사용할 거니까 content 시리즈로 만들기 #####\n","news_content = benchmark['content']\n","news_content"],"metadata":{"id":"OnsJQLlCljKc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 전처리 완료된 content 데이터 : newsnews\n","newsnews = news_content\n","newsnews = newsnews.str.replace(\"\\(.*\\)|\\s-\\s.*\",\" \" ,regex=True)\n","newsnews = newsnews.str.replace(\"\\[.*\\]|\\s-\\s.*\",\" \",regex=True)\n","newsnews = newsnews.str.replace(\"\\<.*\\>|\\s-\\s.*\",\" \",regex=True)\n","newsnews = newsnews.str.replace(\"무단전재 및 재배포 금지\",\" \",regex=True)\n","newsnews = newsnews.str.replace(\"무단 전재 및 재배포 금지\",\" \",regex=True)\n","newsnews = newsnews.str.replace(\"©\",\" \",regex=True)\n","newsnews = newsnews.str.replace(\"ⓒ\",\" \",regex=True)\n","newsnews = newsnews.str.replace(\"저작권자\",\" \",regex=True)\n","newsnews = newsnews.str.replace(\".* 기자\", \" \", regex=True) #기자 이름에서 오는 유사도 차단\n","newsnews = newsnews.str.replace(\"사진 = .*\", \" \", regex=True) #사진 첨부 문구 삭제\n","newsnews = newsnews.str.replace(\"사진=.*\", \" \", regex=True) #사진 첨부 문구 삭제\n","newsnews = newsnews.str.replace('\\\"', \"\",regex=True)\n","newsnews = newsnews.str.replace(\"([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+.[a-zA-Z0-9-.]+)\", \" \", regex=True) #이메일 주소에서 오는 유사도 차단\n","newsnews = newsnews.str.replace(\"\\n\",\" \")\n","newsnews = newsnews.str.replace(\"\\r\",\" \")\n","newsnews = newsnews.str.replace(\"\\t\",\" \")\n","newsnews = newsnews.str.replace( \"\\’\" , \"\", regex=True)\n","# newsnews = newsnews.str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\" \")\n","newsnews = newsnews.str.replace(\"[ ]{2,}\",\" \",regex=True)"],"metadata":{"id":"Cf7-DFZ_llZ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["########## 문장토큰화 ##########\n","!pip install kss\n","import kss\n","import numpy as np"],"metadata":{"id":"lx0Zp6gZlyK4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["con_sen_li = []\n","for i in range(len(newsnews)) :\n","  con_sen_li.append(kss.split_sentences(newsnews[i]))"],"metadata":{"id":"8hkbSmhZl4yQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### final_data : 뽑은 피처값들과 필요한 데이터들을 하나의 데이터프레임으로 만들기 #####\n","keep_columns = ['news_id', 'title', 'content', 'enveloped_at', 'provider']\n","final_data = benchmark[keep_columns]"],"metadata":{"id":"ziEd9fcMmBQT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### 토큰화 된 문장 final_data에 새로운 column으로 붙이기 #####\n","final_data = final_data.assign(con_sen_li = con_sen_li)"],"metadata":{"id":"cujuN1OImMXS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### 토큰화 된 문장 수 구해서 final_data에 새로운 column으로 붙이기 #####\n","count_sen = [0] *60000\n","for i in range(len(con_sen_li)) :\n","  count_sen[i] = len(con_sen_li[i])\n","\n","final_data = final_data.assign(count_sen = count_sen)"],"metadata":{"id":"ckHzue_0mcVW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_data.to_csv('final_final_data.csv', encoding = 'utf-8-sig') #(데이터 손실 방지하기 위해 틈틈이 CSV로 저장)"],"metadata":{"id":"DKEda51SmejT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["########## pos tagging : numpy 배열로 하면 시간 절약 ##########\n","content_array = newsnews.to_numpy()"],"metadata":{"id":"vuejGu48msEI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install konlpy"],"metadata":{"id":"NJiuUDHDnPh_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from konlpy.tag import Okt"],"metadata":{"id":"Gq3MUBlXnP-_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["con_pos = []\n","for i in range(len(content_array)) :\n","  okt = Okt()\n","  con_pos.append(okt.pos(content_array[i]))"],"metadata":{"id":"vgeytbTfnRiP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### pos 태깅 된 데이터 final_data에 새로운 column으로 붙이기 #####\n","final_data = final_data.assign(con_sen_li = con_sen_li)\n","final_data = final_data.assign(con_pos = con_pos)"],"metadata":{"id":"a8hO6Zhini1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### pos 태깅 된 데이터에서 기사별 품사 개수 새로운 column으로 붙이기 #####\n","pos = []\n","count_noun = []\n","count_adjective = []\n","count_verb = []\n","count_determiner = []\n","count_adverb = []\n","count_conjunction = []\n","count_josa = []\n","\n","for con_index in range(len(con_pos)) :\n","  pospos = []\n","  for sen_index in range(len(con_pos[con_index])) :\n","    pospos.append(con_pos[con_index][sen_index][1])\n","  pos.append(pospos)\n","  count_noun.append(pos[con_index].count('Noun'))\n","  count_adjective.append(pos[con_index].count('Adjective'))\n","  count_verb.append(pos[con_index].count('Verb'))\n","  count_determiner.append(pos[con_index].count('Determiner'))\n","  count_adverb.append(pos[con_index].count('Adverb'))\n","  count_conjunction.append(pos[con_index].count('Conjunction'))\n","  count_josa.append(pos[con_index].count('Josa'))"],"metadata":{"id":"MIRGfygInx1a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### 기사별 품사 개수 final_data에 새로운 column으로 붙이기 #####\n","final_data = final_data.assign(count_noun = count_noun)\n","final_data = final_data.assign(count_adjective = count_adjective)\n","final_data = final_data.assign(count_verb = count_verb)\n","final_data = final_data.assign(count_determiner = count_determiner)\n","final_data = final_data.assign(count_adverb = count_adverb)\n","final_data = final_data.assign(count_conjunction = count_conjunction)\n","final_data = final_data.assign(count_josa = count_josa)"],"metadata":{"id":"KK7bwcy3n5G8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_data.to_csv('final_final_data.csv', encoding = 'utf-8-sig') #(데이터 손실 방지하기 위해 틈틈이 CSV로 저장)"],"metadata":{"id":"js-HYm1Cn_6t"},"execution_count":null,"outputs":[]}]}